{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sb7Epo0VOB58"
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fHpCNRv1OB5-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# this allows plots to appear directly in the notebook\n",
    "%matplotlib inline\n",
    "import keras \n",
    "from keras.datasets import mnist \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Dropout \n",
    "from keras.optimizers import SGD \n",
    "from keras import utils \n",
    "import numpy as np \n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnSsH8sNOB6F",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Reset Default graph - Needed only for Jupyter notebook\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DxJDmJqqOB6K",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FhllFLyKOB6N"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B4yQKMiJOB6R"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./prices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fgkX6SEqOB6W"
   },
   "source": [
    "### Check all columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7K8pWsNQOB6X"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date       object\n",
       "symbol     object\n",
       "open      float64\n",
       "close     float64\n",
       "low       float64\n",
       "high      float64\n",
       "volume    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7dU6X7MpOB6c"
   },
   "source": [
    "### Drop columns `date` and  `symbol`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lh_6spSKOB6e"
   },
   "outputs": [],
   "source": [
    "data.drop(['date', 'symbol'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xlwbUgTwOB6i",
    "outputId": "56bad82a-f271-415a-e0d6-cbe1c4290743"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.430000</td>\n",
       "      <td>125.839996</td>\n",
       "      <td>122.309998</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>2163600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125.239998</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>119.940002</td>\n",
       "      <td>125.540001</td>\n",
       "      <td>2386400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.379997</td>\n",
       "      <td>114.949997</td>\n",
       "      <td>114.930000</td>\n",
       "      <td>119.739998</td>\n",
       "      <td>2489500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115.480003</td>\n",
       "      <td>116.620003</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>117.440002</td>\n",
       "      <td>2006300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117.010002</td>\n",
       "      <td>114.970001</td>\n",
       "      <td>114.089996</td>\n",
       "      <td>117.330002</td>\n",
       "      <td>1408600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         open       close         low        high     volume\n",
       "0  123.430000  125.839996  122.309998  126.250000  2163600.0\n",
       "1  125.239998  119.980003  119.940002  125.540001  2386400.0\n",
       "2  116.379997  114.949997  114.930000  119.739998  2489500.0\n",
       "3  115.480003  116.620003  113.500000  117.440002  2006300.0\n",
       "4  117.010002  114.970001  114.089996  117.330002  1408600.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3DBv3WWYOB6q"
   },
   "source": [
    "### Consider only first 1000 rows in the dataset for building feature set and target set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_hG9rGBOB6s"
   },
   "outputs": [],
   "source": [
    "df_prices = data.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "prices_col = df_prices.columns\n",
    "df_prices = scaler.fit_transform(df_prices)\n",
    "df_prices = pd.DataFrame(df_prices, columns=prices_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.972495</td>\n",
       "      <td>1.012559</td>\n",
       "      <td>0.973227</td>\n",
       "      <td>1.003826</td>\n",
       "      <td>-0.217909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.003498</td>\n",
       "      <td>0.912099</td>\n",
       "      <td>0.932280</td>\n",
       "      <td>0.991731</td>\n",
       "      <td>-0.202500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.851734</td>\n",
       "      <td>0.825867</td>\n",
       "      <td>0.845721</td>\n",
       "      <td>0.892928</td>\n",
       "      <td>-0.195369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.836318</td>\n",
       "      <td>0.854497</td>\n",
       "      <td>0.821015</td>\n",
       "      <td>0.853748</td>\n",
       "      <td>-0.228789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.862526</td>\n",
       "      <td>0.826210</td>\n",
       "      <td>0.831208</td>\n",
       "      <td>0.851874</td>\n",
       "      <td>-0.270128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.836832</td>\n",
       "      <td>0.836153</td>\n",
       "      <td>0.838292</td>\n",
       "      <td>0.830239</td>\n",
       "      <td>-0.291610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.853104</td>\n",
       "      <td>0.789866</td>\n",
       "      <td>0.805292</td>\n",
       "      <td>0.847445</td>\n",
       "      <td>-0.301874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.802574</td>\n",
       "      <td>0.816095</td>\n",
       "      <td>0.761408</td>\n",
       "      <td>0.812693</td>\n",
       "      <td>-0.313238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.799490</td>\n",
       "      <td>0.784380</td>\n",
       "      <td>0.793716</td>\n",
       "      <td>0.810138</td>\n",
       "      <td>-0.291908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.805143</td>\n",
       "      <td>0.747521</td>\n",
       "      <td>0.758298</td>\n",
       "      <td>0.827003</td>\n",
       "      <td>-0.262181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       open     close       low      high    volume\n",
       "0  0.972495  1.012559  0.973227  1.003826 -0.217909\n",
       "1  1.003498  0.912099  0.932280  0.991731 -0.202500\n",
       "2  0.851734  0.825867  0.845721  0.892928 -0.195369\n",
       "3  0.836318  0.854497  0.821015  0.853748 -0.228789\n",
       "4  0.862526  0.826210  0.831208  0.851874 -0.270128\n",
       "5  0.836832  0.836153  0.838292  0.830239 -0.291610\n",
       "6  0.853104  0.789866  0.805292  0.847445 -0.301874\n",
       "7  0.802574  0.816095  0.761408  0.812693 -0.313238\n",
       "8  0.799490  0.784380  0.793716  0.810138 -0.291908\n",
       "9  0.805143  0.747521  0.758298  0.827003 -0.262181"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prices.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M3UaApqYOB6x"
   },
   "source": [
    "### Divide the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_prices.drop(['close'], axis=1)\n",
    "y = df_prices['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2EkKAy7fOB6y"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v6vE4eYCOB62",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building the graph in tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xK0zBd1VOB64",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1.Define input data placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 700\n",
    "n_features  =4\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDrYlWTuOB66"
   },
   "outputs": [],
   "source": [
    "X_in = tf.placeholder(tf.float32, [None, n_features], \"X_in\") \n",
    "y_in = tf.placeholder(tf.float32, [None], \"y_in\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "297_qja4OB7A",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2.Define Weights and Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model weights and bias \n",
    "\n",
    "W = tf.Variable(tf.random_normal([n_features,1]), name=\"W\")\n",
    "b = tf.Variable(np.random.randn(), name=\"b\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HgtWA-UIOB7F",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3.Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JveGlx25OB7H"
   },
   "outputs": [],
   "source": [
    "# Construct a linear model \n",
    "h = tf.add(tf.matmul(X_in, W), b)      # can use matmul function too = tf.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TL1hIwf_OB7M",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "4.Loss (Cost) Function [Mean square error]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8VSWPiGXOB7P"
   },
   "outputs": [],
   "source": [
    "# Mean squared error \n",
    "cost = tf.reduce_mean(tf.square(tf.subtract(y_in, h)))     #(loss func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jzG85FUlOB7U",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "5.GradientDescent Optimizer to minimize Loss [GradientDescentOptimizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cj802w-3OB7X"
   },
   "outputs": [],
   "source": [
    "# Gradient descent \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost) # opearational tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xSypb_u8OB7e",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Execute the Graph for 100 epochs and observe the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the variables \n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9smwOW-1OB7k"
   },
   "outputs": [],
   "source": [
    "training_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9JuLI6bSOB7n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    10 \t Cost:     3.567\n",
      "Epoch:    20 \t Cost:     2.414\n",
      "Epoch:    30 \t Cost:     1.875\n",
      "Epoch:    40 \t Cost:      1.58\n",
      "Epoch:    50 \t Cost:     1.402\n",
      "Epoch:    60 \t Cost:      1.29\n",
      "Epoch:    70 \t Cost:     1.218\n",
      "Epoch:    80 \t Cost:     1.171\n",
      "Epoch:    90 \t Cost:     1.141\n",
      "Epoch:   100 \t Cost:      1.12\n",
      "Optimization Finished!\n",
      "Final training cost: 1.1204737 W: [[-2.6616518 ]\n",
      " [ 1.6774362 ]\n",
      " [ 0.9815274 ]\n",
      " [ 0.03951158]] b: 0.22093138 \n",
      "\n",
      "Final testing cost: 0.88917863\n",
      "Absolute mean square loss difference: 0.23129511\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph \n",
    "with tf.Session() as sess: \n",
    "\t# Load initialized variables in current session \n",
    "\tsess.run(init) \n",
    "\n",
    "\t# Fit all training data \n",
    "\tfor epoch in range(training_epochs): \n",
    "\n",
    "\t\t# perform gradient descent step \n",
    "\t\tsess.run(optimizer, feed_dict={X_in: X_train, y_in: y_train}) \n",
    "\t\t\n",
    "\t\t# Display logs per epoch step \n",
    "\t\tif (epoch+1) % 10 == 0: \n",
    "\t\t\tc = sess.run(cost, feed_dict={X_in: X_train, y_in: y_train}) \n",
    "\t\t\tprint(\"Epoch:{0:6} \\t Cost:{1:10.4}\". \n",
    "\t\t\t\tformat(epoch+1, c)) \n",
    "\t\t\t\n",
    "\t# Print final parameter values \n",
    "\tprint(\"Optimization Finished!\") \n",
    "\ttraining_cost = sess.run(cost, feed_dict={X_in: X_train, y_in: y_train}) \n",
    "\tprint(\"Final training cost:\", training_cost, \"W:\", sess.run(W), \"b:\", \n",
    "\t\tsess.run(b), '\\n') \n",
    "\t\n",
    "\t# Testing the model \n",
    "\ttesting_cost = sess.run(tf.reduce_mean(tf.square(tf.subtract(y_in, h))), \n",
    "\t\t\t\t\t\t\tfeed_dict={X_in: X_test, y_in: y_test}) \n",
    "\t\n",
    "\tprint(\"Final testing cost:\", testing_cost) \n",
    "\tlossdiff = abs(training_cost - testing_cost)\n",
    "\tprint(\"Absolute mean square loss difference:\", lossdiff) \n",
    "\tWeight = sess.run(W)\n",
    "\tBias = sess.run(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DOL2ncA1OB7q"
   },
   "source": [
    "### Get the shapes and values of W and b\n",
    "\n",
    "Hint: Use sess.run(W) to get W."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZGvtyTeuOB7r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "print(Weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vhDtOv5UOB7x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "print(Bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SZqKUEFsOB71"
   },
   "source": [
    "### Find the Absolute mean square loss difference between training and testing loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97t-grQgOB71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24467516\n"
     ]
    }
   ],
   "source": [
    "print(lossdiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KjOInjUROB75"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CZUAjZ5oOB78"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YJRBuqXhOB7_"
   },
   "source": [
    "### Linear Classification using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GoNTWXAOB8C",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Building the simple Neural Network in Keras with one neuron in the dense hidden layer.\n",
    "#### Use Mean square error as loss function and sgd as optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 25\n",
      "Trainable params: 25\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() # the first layer has to specify the dimensions of the input vector \n",
    "model.add( Dense( units = 4, input_shape =( 4,))) \n",
    "model.add( Dense( units = 1)) \n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zpeL5rCTOB8D"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wt-HYFMEOB8G",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "66JGJt7GOB8H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: 1.3808e-04\n",
      "Epoch 2/100\n",
      "700/700 [==============================] - 0s 27us/step - loss: 1.3804e-04\n",
      "Epoch 3/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: 1.3767e-04\n",
      "Epoch 4/100\n",
      "700/700 [==============================] - 0s 50us/step - loss: 1.3816e-04\n",
      "Epoch 5/100\n",
      "700/700 [==============================] - 0s 43us/step - loss: 1.3818e-04\n",
      "Epoch 6/100\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3786e-04\n",
      "Epoch 7/100\n",
      "700/700 [==============================] - 0s 33us/step - loss: 1.3801e-04\n",
      "Epoch 8/100\n",
      "700/700 [==============================] - 0s 41us/step - loss: 1.3812e-04\n",
      "Epoch 9/100\n",
      "700/700 [==============================] - 0s 46us/step - loss: 1.3803e-04\n",
      "Epoch 10/100\n",
      "700/700 [==============================] - 0s 46us/step - loss: 1.3812e-04\n",
      "Epoch 11/100\n",
      "700/700 [==============================] - 0s 47us/step - loss: 1.3830e-04\n",
      "Epoch 12/100\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.3773e-04\n",
      "Epoch 13/100\n",
      "700/700 [==============================] - 0s 40us/step - loss: 1.3769e-04\n",
      "Epoch 14/100\n",
      "700/700 [==============================] - 0s 44us/step - loss: 1.3788e-04\n",
      "Epoch 15/100\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.3651e-0 - 0s 54us/step - loss: 1.3784e-04\n",
      "Epoch 16/100\n",
      "700/700 [==============================] - 0s 46us/step - loss: 1.3778e-04\n",
      "Epoch 17/100\n",
      "700/700 [==============================] - 0s 43us/step - loss: 1.3852e-04\n",
      "Epoch 18/100\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.3787e-04\n",
      "Epoch 19/100\n",
      "700/700 [==============================] - 0s 33us/step - loss: 1.3822e-04\n",
      "Epoch 20/100\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.3757e-04\n",
      "Epoch 21/100\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3797e-04\n",
      "Epoch 22/100\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3766e-04\n",
      "Epoch 23/100\n",
      "700/700 [==============================] - 0s 48us/step - loss: 1.3803e-04\n",
      "Epoch 24/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: 1.3779e-04\n",
      "Epoch 25/100\n",
      "700/700 [==============================] - 0s 38us/step - loss: 1.3756e-04\n",
      "Epoch 26/100\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.3842e-04\n",
      "Epoch 27/100\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3766e-04\n",
      "Epoch 28/100\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3811e-04\n",
      "Epoch 29/100\n",
      "700/700 [==============================] - 0s 50us/step - loss: 1.3779e-04\n",
      "Epoch 30/100\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3779e-04\n",
      "Epoch 31/100\n",
      "700/700 [==============================] - 0s 47us/step - loss: 1.3768e-04\n",
      "Epoch 32/100\n",
      "700/700 [==============================] - 0s 34us/step - loss: 1.3772e-04\n",
      "Epoch 33/100\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.3792e-04\n",
      "Epoch 34/100\n",
      "700/700 [==============================] - 0s 37us/step - loss: 1.3755e-04\n",
      "Epoch 35/100\n",
      "700/700 [==============================] - 0s 33us/step - loss: 1.3806e-04\n",
      "Epoch 36/100\n",
      "700/700 [==============================] - 0s 38us/step - loss: 1.3790e-04\n",
      "Epoch 37/100\n",
      "700/700 [==============================] - 0s 34us/step - loss: 1.3767e-04\n",
      "Epoch 38/100\n",
      "700/700 [==============================] - 0s 38us/step - loss: 1.3807e-04\n",
      "Epoch 39/100\n",
      "700/700 [==============================] - 0s 33us/step - loss: 1.3791e-04\n",
      "Epoch 40/100\n",
      "700/700 [==============================] - 0s 41us/step - loss: 1.3812e-04\n",
      "Epoch 41/100\n",
      "700/700 [==============================] - 0s 41us/step - loss: 1.3786e-04\n",
      "Epoch 42/100\n",
      "700/700 [==============================] - 0s 38us/step - loss: 1.3771e-04\n",
      "Epoch 43/100\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.7046e-0 - 0s 36us/step - loss: 1.3774e-04\n",
      "Epoch 44/100\n",
      "700/700 [==============================] - 0s 38us/step - loss: 1.3761e-04\n",
      "Epoch 45/100\n",
      "700/700 [==============================] - 0s 40us/step - loss: 1.3799e-04\n",
      "Epoch 46/100\n",
      "700/700 [==============================] - 0s 37us/step - loss: 1.3822e-04\n",
      "Epoch 47/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: 1.3879e-04\n",
      "Epoch 48/100\n",
      "700/700 [==============================] - 0s 41us/step - loss: 1.3794e-04\n",
      "Epoch 49/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: 1.3780e-04\n",
      "Epoch 50/100\n",
      "700/700 [==============================] - 0s 44us/step - loss: 1.3809e-04\n",
      "Epoch 51/100\n",
      "700/700 [==============================] - 0s 38us/step - loss: 1.3781e-04\n",
      "Epoch 52/100\n",
      "700/700 [==============================] - 0s 41us/step - loss: 1.3780e-04\n",
      "Epoch 53/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: 1.3736e-04\n",
      "Epoch 54/100\n",
      "700/700 [==============================] - 0s 38us/step - loss: 1.3806e-04\n",
      "Epoch 55/100\n",
      "700/700 [==============================] - 0s 40us/step - loss: 1.3737e-04\n",
      "Epoch 56/100\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3757e-04\n",
      "Epoch 57/100\n",
      "700/700 [==============================] - 0s 48us/step - loss: 1.3804e-04\n",
      "Epoch 58/100\n",
      "700/700 [==============================] - 0s 41us/step - loss: 1.3758e-04\n",
      "Epoch 59/100\n",
      "700/700 [==============================] - 0s 43us/step - loss: 1.3798e-04\n",
      "Epoch 60/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: 1.3770e-04\n",
      "Epoch 61/100\n",
      "700/700 [==============================] - 0s 46us/step - loss: 1.3748e-04\n",
      "Epoch 62/100\n",
      "700/700 [==============================] - 0s 51us/step - loss: 1.3791e-04\n",
      "Epoch 63/100\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.3769e-04\n",
      "Epoch 64/100\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.3714e-04\n",
      "Epoch 65/100\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3763e-04\n",
      "Epoch 66/100\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3804e-04\n",
      "Epoch 67/100\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3800e-04\n",
      "Epoch 68/100\n",
      "700/700 [==============================] - 0s 51us/step - loss: 1.3758e-04\n",
      "Epoch 69/100\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3768e-04\n",
      "Epoch 70/100\n",
      "700/700 [==============================] - 0s 51us/step - loss: 1.3769e-04\n",
      "Epoch 71/100\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.3785e-04\n",
      "Epoch 72/100\n",
      "700/700 [==============================] - 0s 50us/step - loss: 1.3770e-04\n",
      "Epoch 73/100\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3811e-04\n",
      "Epoch 74/100\n",
      "700/700 [==============================] - 0s 50us/step - loss: 1.3723e-04\n",
      "Epoch 75/100\n",
      "700/700 [==============================] - 0s 41us/step - loss: 1.3780e-04\n",
      "Epoch 76/100\n",
      "700/700 [==============================] - 0s 44us/step - loss: 1.3779e-04\n",
      "Epoch 77/100\n",
      "700/700 [==============================] - 0s 40us/step - loss: 1.3766e-04\n",
      "Epoch 78/100\n",
      "700/700 [==============================] - 0s 38us/step - loss: 1.3774e-04\n",
      "Epoch 79/100\n",
      "700/700 [==============================] - 0s 31us/step - loss: 1.3782e-04\n",
      "Epoch 80/100\n",
      "700/700 [==============================] - 0s 41us/step - loss: 1.3765e-04\n",
      "Epoch 81/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: 1.3785e-04\n",
      "Epoch 82/100\n",
      "700/700 [==============================] - 0s 41us/step - loss: 1.3792e-04\n",
      "Epoch 83/100\n",
      "700/700 [==============================] - 0s 40us/step - loss: 1.3771e-04\n",
      "Epoch 84/100\n",
      "700/700 [==============================] - 0s 38us/step - loss: 1.3761e-04\n",
      "Epoch 85/100\n",
      "700/700 [==============================] - 0s 41us/step - loss: 1.3756e-04\n",
      "Epoch 86/100\n",
      "700/700 [==============================] - 0s 37us/step - loss: 1.3735e-04\n",
      "Epoch 87/100\n",
      "700/700 [==============================] - 0s 40us/step - loss: 1.3742e-04\n",
      "Epoch 88/100\n",
      "700/700 [==============================] - 0s 33us/step - loss: 1.3777e-04\n",
      "Epoch 89/100\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3689e-04\n",
      "Epoch 90/100\n",
      "700/700 [==============================] - 0s 44us/step - loss: 1.3789e-04\n",
      "Epoch 91/100\n",
      "700/700 [==============================] - 0s 37us/step - loss: 1.3810e-04\n",
      "Epoch 92/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: 1.3830e-04\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 41us/step - loss: 1.3778e-04\n",
      "Epoch 94/100\n",
      "700/700 [==============================] - 0s 44us/step - loss: 1.3719e-04\n",
      "Epoch 95/100\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.3782e-04\n",
      "Epoch 96/100\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3752e-04\n",
      "Epoch 97/100\n",
      "700/700 [==============================] - 0s 51us/step - loss: 1.3795e-04\n",
      "Epoch 98/100\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3747e-04\n",
      "Epoch 99/100\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.3799e-04\n",
      "Epoch 100/100\n",
      "700/700 [==============================] - 0s 47us/step - loss: 1.3753e-04\n",
      "300/300 [==============================] - 0s 30us/step\n",
      "\\ n loss: 0.0001372928974402991\n"
     ]
    }
   ],
   "source": [
    "# train the model \n",
    "model.fit(X_train, y_train, epochs = 100) \n",
    "\n",
    "# evaluate the model and print the accuracy score \n",
    "\n",
    "loss = model.evaluate(X_test, y_test) \n",
    "\n",
    "print('\\ n loss:', loss) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UbUPQ2iGTyOC"
   },
   "source": [
    "### Classification using Keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YxJfb_2vTyOD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hRouHBtITyOF"
   },
   "source": [
    "### Load the given Iris data using pandas (Iris.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yEN7BRzvTyOF"
   },
   "outputs": [],
   "source": [
    "data_iris = pd.read_csv('./iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8wbhz0SgTyOI"
   },
   "source": [
    "### Splitting the data into feature set and target set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "If4kadhPTyOJ"
   },
   "outputs": [],
   "source": [
    "X_i = data_iris.drop(['Id','Species'], axis=1)\n",
    "Y_i = data_iris['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_i = stats.zscore(X_i, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QuLlR5E8TyOP"
   },
   "source": [
    "### Target set has different categories. So, Label encode them. And convert into one-hot vectors using get_dummies in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lui4BZRgTyOR"
   },
   "outputs": [],
   "source": [
    "Y_i = pd.get_dummies(Y_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QBCfIFH8TyOV"
   },
   "source": [
    "### Divide the dataset into Training and test (70:30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ocEfx5TvTyOW"
   },
   "outputs": [],
   "source": [
    "Xi_train, Xi_test, yi_train, yi_test = train_test_split(X_i, Y_i, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N31GZ7-YTyOY"
   },
   "source": [
    "### Model\n",
    "Build the model with following layers: <br>\n",
    "1. First dense layer with 10 neurons with input shape 4 (according to the feature set) <br>\n",
    "2. Second Dense layer with 8 neurons <br>\n",
    "3. Output layer with 3 neurons with softmax activation (output layer, 3 neurons as we have 3 classes) <br>\n",
    "4. Use SGD and categorical_crossentropy loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5mNXvtQiTyOa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 165\n",
      "Trainable params: 165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() # the first layer has to specify the dimensions of the input vector \n",
    "model.add( Dense( units = 10, activation ='sigmoid', input_shape =( 4,))) # add dropout layer for preventing overfitting \n",
    "model.add( Dense( units = 8, activation ='sigmoid')) \n",
    "model.add( Dense( units = 3, activation ='softmax')) # print the summary of our model \n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IMqTdhwfTyOf"
   },
   "source": [
    "### Fitting the model and predicting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z9tI_ZAJTyOg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1583 - acc: 0.3619\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 1.1507 - acc: 0.3619\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 0s 85us/step - loss: 1.1448 - acc: 0.3619\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 1.1400 - acc: 0.3619\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 0s 95us/step - loss: 1.1356 - acc: 0.3619\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 0s 95us/step - loss: 1.1317 - acc: 0.3619\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 0s 85us/step - loss: 1.1267 - acc: 0.3619\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 1.1235 - acc: 0.3619\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 1.1202 - acc: 0.3619\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 0s 66us/step - loss: 1.1177 - acc: 0.3619\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 0s 95us/step - loss: 1.1155 - acc: 0.3619\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 1.1123 - acc: 0.3619\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 0s 85us/step - loss: 1.1107 - acc: 0.3619\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 1.1092 - acc: 0.3619\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 0s 85us/step - loss: 1.1072 - acc: 0.3619\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 0s 66us/step - loss: 1.1063 - acc: 0.3619\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 0s 95us/step - loss: 1.1053 - acc: 0.3619\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 1.1046 - acc: 0.3619\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 1.1036 - acc: 0.3619\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 0s 95us/step - loss: 1.1034 - acc: 0.3619\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 0s 85us/step - loss: 1.1015 - acc: 0.3619\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 1.1007 - acc: 0.3619\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 1.0997 - acc: 0.3619\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 0s 66us/step - loss: 1.0989 - acc: 0.3619\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 1.0977 - acc: 0.3619\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 0s 95us/step - loss: 1.0969 - acc: 0.3619\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 1.0963 - acc: 0.3619\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 1.0958 - acc: 0.3619\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 0s 95us/step - loss: 1.0954 - acc: 0.3619\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 1.0946 - acc: 0.3619\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 0s 66us/step - loss: 1.0937 - acc: 0.3619\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 1.0935 - acc: 0.3619\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 1.0930 - acc: 0.3619\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 1.0926 - acc: 0.3619\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 0s 114us/step - loss: 1.0925 - acc: 0.3619\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 1.0920 - acc: 0.3619\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 0s 123us/step - loss: 1.0916 - acc: 0.3619\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 0s 104us/step - loss: 1.0909 - acc: 0.3619\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 0s 66us/step - loss: 1.0903 - acc: 0.3619\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 0s 85us/step - loss: 1.0901 - acc: 0.3619\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 0s 104us/step - loss: 1.0904 - acc: 0.3619\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 1.0896 - acc: 0.3619\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 0s 95us/step - loss: 1.0895 - acc: 0.3619\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 0s 105us/step - loss: 1.0892 - acc: 0.3619\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 0s 66us/step - loss: 1.0887 - acc: 0.3619\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 0s 66us/step - loss: 1.0886 - acc: 0.3619\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 0s 123us/step - loss: 1.0887 - acc: 0.3619\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 0s 95us/step - loss: 1.0883 - acc: 0.3619\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 0s 66us/step - loss: 1.0883 - acc: 0.3619\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 1.0879 - acc: 0.3619\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 1.0879 - acc: 0.3619\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 0s 104us/step - loss: 1.0880 - acc: 0.3619\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 0s 85us/step - loss: 1.0876 - acc: 0.3619\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 0s 114us/step - loss: 1.0874 - acc: 0.3619\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 0s 95us/step - loss: 1.0873 - acc: 0.3619\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 0s 85us/step - loss: 1.0874 - acc: 0.3619\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 0s 104us/step - loss: 1.0869 - acc: 0.3619\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 0s 133us/step - loss: 1.0867 - acc: 0.3619\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 0s 85us/step - loss: 1.0866 - acc: 0.3619\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 0s 85us/step - loss: 1.0865 - acc: 0.3619\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 0s 104us/step - loss: 1.0861 - acc: 0.3619\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 0s 95us/step - loss: 1.0860 - acc: 0.3619\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 0s 85us/step - loss: 1.0857 - acc: 0.3619\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 0s 85us/step - loss: 1.0858 - acc: 0.3619\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 0s 85us/step - loss: 1.0855 - acc: 0.3619\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 1.0854 - acc: 0.3619\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 0s 105us/step - loss: 1.0852 - acc: 0.3619\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 0s 104us/step - loss: 1.0851 - acc: 0.3619\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 1.0850 - acc: 0.3619\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 0s 85us/step - loss: 1.0850 - acc: 0.3619\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 0s 123us/step - loss: 1.0846 - acc: 0.3619\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 1.0843 - acc: 0.3619\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 0s 66us/step - loss: 1.0844 - acc: 0.3619\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 0s 104us/step - loss: 1.0843 - acc: 0.3619\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 0s 85us/step - loss: 1.0842 - acc: 0.3619\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 0s 104us/step - loss: 1.0838 - acc: 0.3619\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 0s 104us/step - loss: 1.0836 - acc: 0.3619\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 0s 85us/step - loss: 1.0835 - acc: 0.3619\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 0s 95us/step - loss: 1.0831 - acc: 0.3619\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 0s 95us/step - loss: 1.0830 - acc: 0.3619\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 0s 95us/step - loss: 1.0830 - acc: 0.3619\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 0s 104us/step - loss: 1.0829 - acc: 0.3619\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 0s 427us/step - loss: 1.0826 - acc: 0.3619\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 104us/step - loss: 1.0826 - acc: 0.3619\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 0s 95us/step - loss: 1.0822 - acc: 0.3619\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 0s 95us/step - loss: 1.0821 - acc: 0.3619\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 0s 95us/step - loss: 1.0819 - acc: 0.3619\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 0s 95us/step - loss: 1.0817 - acc: 0.3619\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 1.0818 - acc: 0.3619\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 0s 95us/step - loss: 1.0817 - acc: 0.3619\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 0s 85us/step - loss: 1.0816 - acc: 0.3619\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 0s 104us/step - loss: 1.0812 - acc: 0.3619\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 0s 85us/step - loss: 1.0810 - acc: 0.3619\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 1.0808 - acc: 0.3619\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 0s 95us/step - loss: 1.0807 - acc: 0.3619\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 0s 95us/step - loss: 1.0806 - acc: 0.3619\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 0s 114us/step - loss: 1.0806 - acc: 0.3619\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 1.0803 - acc: 0.3619\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 0s 104us/step - loss: 1.0800 - acc: 0.3619\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 1.0798 - acc: 0.3619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12e654f6c18>"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile( loss ='categorical_crossentropy', optimizer = SGD(), metrics =['accuracy']) \n",
    "\n",
    "# train the model \n",
    "model.fit(Xi_train, yi_train, epochs = 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e4-Rfd5iTyOj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.689485  ,  1.59026379,  0.70060572, -0.46707048, -1.13431403],\n",
       "       [-0.18928292,  1.64045201,  0.44166016, -0.56784877, -1.32498047],\n",
       "       [ 0.33143213,  1.41496023,  0.45890602, -0.75209598, -1.4532024 ],\n",
       "       [ 0.81400877,  1.18401276,  0.25900279, -0.72767451, -1.52934982],\n",
       "       [ 1.01208567,  1.01208567,  0.28916733, -0.84684719, -1.46649148],\n",
       "       [ 1.17834225,  0.89778457,  0.19639038, -0.83232112, -1.44019609],\n",
       "       [ 1.54685328,  0.53252326,  0.02535825, -0.81991677, -1.28481803],\n",
       "       [ 1.60303038,  0.50506437, -0.08051751, -0.77589598, -1.25168125],\n",
       "       [ 1.77370608,  0.26834668, -0.22253139, -0.71340945, -1.10611191],\n",
       "       [ 1.76923689,  0.28517305, -0.23861419, -0.70420284, -1.11159291],\n",
       "       [ 1.76093253,  0.27580871, -0.17503245, -0.75847395, -1.10323484],\n",
       "       [ 1.84981106,  0.09735848, -0.24339619, -0.68150934, -1.02226401],\n",
       "       [ 1.87656507,  0.07471102, -0.32081792, -0.67239919, -0.95805898],\n",
       "       [ 1.91181327, -0.0402487 , -0.30186525, -0.68422791, -0.88547141],\n",
       "       [ 1.85220917,  0.1062743 , -0.23532166, -0.76669314, -0.95646867],\n",
       "       [ 1.87724408,  0.01805042, -0.21660509, -0.74006738, -0.93862204],\n",
       "       [ 1.90839419, -0.0334806 , -0.2845851 , -0.7198329 , -0.8704956 ],\n",
       "       [ 1.93127721, -0.08764305, -0.33805177, -0.6667132 , -0.8388692 ],\n",
       "       [ 1.92361701, -0.05964704, -0.34297048, -0.65611743, -0.86488207],\n",
       "       [ 1.94348809, -0.14583172, -0.32812137, -0.65063382, -0.81890119],\n",
       "       [ 1.94630428, -0.12479714, -0.39032296, -0.61601991, -0.81516427],\n",
       "       [ 1.95632893, -0.18221951, -0.35937737, -0.63776829, -0.77696375],\n",
       "       [ 1.96275396, -0.22336425, -0.34217502, -0.65108303, -0.74613165],\n",
       "       [ 1.96801361, -0.20970637, -0.41710827, -0.60146552, -0.73973345],\n",
       "       [ 1.97147142, -0.24835705, -0.40220654, -0.56704529, -0.75386254],\n",
       "       [ 1.97221379, -0.22611368, -0.4354782 , -0.58203337, -0.72858853],\n",
       "       [ 1.97478621, -0.25089497, -0.41276269, -0.59486388, -0.71626467],\n",
       "       [ 1.97241027, -0.24072724, -0.40574188, -0.59987675, -0.72606441],\n",
       "       [ 1.97443047, -0.24633726, -0.41429448, -0.60091362, -0.7128851 ],\n",
       "       [ 1.98150676, -0.29102819, -0.42576346, -0.56948109, -0.69523401],\n",
       "       [ 1.98228493, -0.28962518, -0.4370392 , -0.56711039, -0.68851016],\n",
       "       [ 1.97924019, -0.26491109, -0.43364427, -0.59394079, -0.68674404],\n",
       "       [ 1.97799256, -0.29237049, -0.382205  , -0.59454112, -0.70887595],\n",
       "       [ 1.97728377, -0.28224259, -0.38530871, -0.60729726, -0.70243521],\n",
       "       [ 1.98506675, -0.30598038, -0.44298652, -0.56476976, -0.67133009],\n",
       "       [ 1.98502324, -0.30425207, -0.43717774, -0.58487292, -0.65872051],\n",
       "       [ 1.98259805, -0.2883779 , -0.43256685, -0.59117469, -0.67047861],\n",
       "       [ 1.98745491, -0.32240315, -0.44801477, -0.55966954, -0.65736746],\n",
       "       [ 1.99055872, -0.35047907, -0.44520314, -0.56022523, -0.63465129],\n",
       "       [ 1.98776911, -0.32775632, -0.44054696, -0.56660708, -0.65285875],\n",
       "       [ 1.9886742 , -0.33726054, -0.43417448, -0.57631494, -0.64092424],\n",
       "       [ 1.9924426 , -0.34830294, -0.48562667, -0.54804655, -0.61046644],\n",
       "       [ 1.99203805, -0.3680807 , -0.44145226, -0.55762391, -0.62488118],\n",
       "       [ 1.99160096, -0.35783756, -0.44820058, -0.5626604 , -0.62290242],\n",
       "       [ 1.99103401, -0.36211341, -0.43878238, -0.55083702, -0.63930121],\n",
       "       [ 1.99247136, -0.35967248, -0.46243605, -0.55378144, -0.61658139],\n",
       "       [ 1.99088354, -0.3615705 , -0.43455834, -0.55807621, -0.63667849],\n",
       "       [ 1.99325024, -0.37550826, -0.45191982, -0.55016327, -0.61565889],\n",
       "       [ 1.99106245, -0.3567365 , -0.4426971 , -0.56089293, -0.63073592],\n",
       "       [ 1.99263182, -0.36582246, -0.45491963, -0.55449881, -0.61739092],\n",
       "       [ 1.99049293, -0.34253022, -0.54401858, -0.4644837 , -0.63946043],\n",
       "       [ 1.99308798, -0.36878343, -0.53452879, -0.46719474, -0.62258102],\n",
       "       [ 1.99156425, -0.35534556, -0.54880017, -0.45716378, -0.63025474],\n",
       "       [ 1.9950016 , -0.38936453, -0.54668353, -0.46310781, -0.59584572],\n",
       "       [ 1.99324527, -0.36922774, -0.54945764, -0.46177823, -0.61278166],\n",
       "       [ 1.99494917, -0.39765796, -0.53560152, -0.45473806, -0.60695163],\n",
       "       [ 1.99467418, -0.38934234, -0.53040841, -0.46457758, -0.61034585],\n",
       "       [ 1.99670612, -0.40858188, -0.52182519, -0.4810576 , -0.58524145],\n",
       "       [ 1.9936479 , -0.37414788, -0.54133957, -0.46452177, -0.61363868],\n",
       "       [ 1.99691993, -0.41558475, -0.52564427, -0.4728157 , -0.58287522],\n",
       "       [ 1.9966094 , -0.40790945, -0.53672296, -0.4723162 , -0.57966079],\n",
       "       [ 1.99618902, -0.40282992, -0.52684338, -0.47552746, -0.59098827],\n",
       "       [ 1.99501044, -0.38596936, -0.54470134, -0.46951251, -0.59482723],\n",
       "       [ 1.99564861, -0.40260906, -0.53515525, -0.46059802, -0.59728628],\n",
       "       [ 1.99687308, -0.40812004, -0.51743791, -0.48909624, -0.58221887],\n",
       "       [ 1.99516206, -0.38634177, -0.53091873, -0.47871038, -0.59919118],\n",
       "       [ 1.99702588, -0.42241747, -0.52486947, -0.46576255, -0.58397639],\n",
       "       [ 1.99626632, -0.40636071, -0.52610579, -0.47202737, -0.59177245],\n",
       "       [ 1.99593844, -0.39979807, -0.55239275, -0.46465081, -0.57909682],\n",
       "       [ 1.99688316, -0.41224527, -0.52821263, -0.47584027, -0.58058499],\n",
       "       [ 1.99730835, -0.42581453, -0.52631271, -0.46675823, -0.57842288],\n",
       "       [ 1.99671862, -0.40619878, -0.52652697, -0.48277127, -0.5812216 ],\n",
       "       [ 1.99624129, -0.40891214, -0.54593737, -0.45939512, -0.58199665],\n",
       "       [ 1.99651365, -0.41392868, -0.53107831, -0.46362853, -0.58787813],\n",
       "       [ 1.99655245, -0.40547312, -0.52802545, -0.47900452, -0.58404937],\n",
       "       [ 1.99650576, -0.40400532, -0.52852751, -0.48010222, -0.58387071],\n",
       "       [ 1.99610654, -0.40168058, -0.53830662, -0.4699936 , -0.58612574],\n",
       "       [ 1.99668027, -0.41135936, -0.53632075, -0.46877405, -0.5802261 ],\n",
       "       [ 1.99748823, -0.42391065, -0.52673718, -0.47366543, -0.57317497],\n",
       "       [ 1.99755883, -0.41810883, -0.51889712, -0.489636  , -0.57091688],\n",
       "       [ 1.99779395, -0.42562255, -0.52512707, -0.48018955, -0.56685477],\n",
       "       [ 1.99779009, -0.42502129, -0.52320058, -0.48202862, -0.56753961],\n",
       "       [ 1.99776659, -0.42414894, -0.52140202, -0.48375567, -0.56845996],\n",
       "       [ 1.99755858, -0.43240975, -0.5352161 , -0.46044784, -0.56948489],\n",
       "       [ 1.99833816, -0.44434792, -0.51799675, -0.47196623, -0.56402726],\n",
       "       [ 1.99809238, -0.43489682, -0.51396897, -0.48051537, -0.56871123],\n",
       "       [ 1.99731273, -0.41811215, -0.52640019, -0.47827217, -0.57452821],\n",
       "       [ 1.99739071, -0.41876003, -0.53705382, -0.47494958, -0.56662727],\n",
       "       [ 1.99831614, -0.43822722, -0.51418661, -0.48204995, -0.56385236],\n",
       "       [ 1.99834359, -0.4369035 , -0.52336198, -0.48013274, -0.55794537],\n",
       "       [ 1.99822785, -0.44037451, -0.52308734, -0.47174834, -0.56301767],\n",
       "       [ 1.99802322, -0.43368824, -0.521445  , -0.47615118, -0.56673881],\n",
       "       [ 1.9981963 , -0.43264518, -0.52185037, -0.4828231 , -0.56087764],\n",
       "       [ 1.99871497, -0.44208679, -0.51613359, -0.48870885, -0.55178575],\n",
       "       [ 1.99845521, -0.44094806, -0.5200786 , -0.47914901, -0.55827954],\n",
       "       [ 1.99841338, -0.44085031, -0.51378511, -0.48136965, -0.56240831],\n",
       "       [ 1.99849563, -0.44149703, -0.51632703, -0.48158453, -0.55908704],\n",
       "       [ 1.99817503, -0.43268195, -0.5200657 , -0.48299381, -0.56243358],\n",
       "       [ 1.99888404, -0.44315618, -0.51077391, -0.4977705 , -0.54718345],\n",
       "       [ 1.9985891 , -0.44206037, -0.51711746, -0.48347118, -0.55594009],\n",
       "       [ 1.99853404, -0.45367085, -0.53135422, -0.46143919, -0.55206978],\n",
       "       [ 1.99863987, -0.45064874, -0.52957592, -0.468471  , -0.54994422],\n",
       "       [ 1.99784728, -0.43416026, -0.53813556, -0.46459206, -0.5609594 ],\n",
       "       [ 1.9982708 , -0.4457835 , -0.53083759, -0.46329463, -0.55835509],\n",
       "       [ 1.99837642, -0.44684193, -0.53372786, -0.46421912, -0.55358751],\n",
       "       [ 1.99736664, -0.43086263, -0.54437742, -0.45553976, -0.56658683],\n",
       "       [ 1.99916664, -0.46360983, -0.52150076, -0.47325832, -0.54079773],\n",
       "       [ 1.99756126, -0.43360165, -0.53982922, -0.45774428, -0.56638611],\n",
       "       [ 1.9980158 , -0.43992571, -0.54001715, -0.46137388, -0.55669906],\n",
       "       [ 1.99839993, -0.44377212, -0.52929565, -0.46990431, -0.55542784],\n",
       "       [ 1.99869279, -0.44586944, -0.52306614, -0.47861955, -0.55113766],\n",
       "       [ 1.99854986, -0.44581967, -0.53146519, -0.47128185, -0.54998314],\n",
       "       [ 1.99849701, -0.44329294, -0.53066396, -0.47318303, -0.55135709],\n",
       "       [ 1.99897354, -0.45666206, -0.52922008, -0.47253413, -0.54055727],\n",
       "       [ 1.99914314, -0.45981643, -0.52737027, -0.47557899, -0.53637745],\n",
       "       [ 1.99893688, -0.45275831, -0.52434065, -0.47736474, -0.54447318],\n",
       "       [ 1.9986084 , -0.44871239, -0.52622934, -0.47086009, -0.55280658],\n",
       "       [ 1.99809826, -0.44200624, -0.52828373, -0.46412867, -0.56367962],\n",
       "       [ 1.99771138, -0.43761476, -0.54920652, -0.45511935, -0.55577075],\n",
       "       [ 1.99870175, -0.44974011, -0.53135484, -0.47121767, -0.54638913],\n",
       "       [ 1.99873636, -0.44873969, -0.5281057 , -0.47448002, -0.54741094],\n",
       "       [ 1.99922286, -0.46227006, -0.52148123, -0.47707285, -0.53839871],\n",
       "       [ 1.99786867, -0.43819581, -0.54172327, -0.45932387, -0.55862572],\n",
       "       [ 1.99890786, -0.45030571, -0.52521793, -0.47943824, -0.54394599],\n",
       "       [ 1.99884238, -0.45307647, -0.52354582, -0.47380275, -0.54841735],\n",
       "       [ 1.99843321, -0.44510184, -0.52737575, -0.46978401, -0.55617161],\n",
       "       [ 1.99903393, -0.45307105, -0.52208725, -0.48148949, -0.54238614],\n",
       "       [ 1.99910301, -0.45646588, -0.51891267, -0.48063883, -0.54308562],\n",
       "       [ 1.99894364, -0.45618048, -0.52827222, -0.47220087, -0.54229006],\n",
       "       [ 1.99844875, -0.44392293, -0.52745682, -0.47176756, -0.55530144],\n",
       "       [ 1.99839074, -0.44329664, -0.5341685 , -0.46897782, -0.55194778],\n",
       "       [ 1.99838873, -0.44303715, -0.52369667, -0.47254673, -0.55910817],\n",
       "       [ 1.99903924, -0.45803229, -0.52790163, -0.47355881, -0.53954651],\n",
       "       [ 1.99895414, -0.45411566, -0.52134937, -0.47716722, -0.54632189],\n",
       "       [ 1.99886107, -0.45825501, -0.52497267, -0.4677861 , -0.54784729],\n",
       "       [ 1.99857966, -0.44395959, -0.53343686, -0.47441994, -0.54676327],\n",
       "       [ 1.99928581, -0.46447673, -0.51914323, -0.4776721 , -0.53799375],\n",
       "       [ 1.99905806, -0.45867775, -0.5203079 , -0.47548597, -0.54458644],\n",
       "       [ 1.99928539, -0.46097513, -0.51646973, -0.48317297, -0.53866757],\n",
       "       [ 1.99903385, -0.45323717, -0.52324941, -0.48087358, -0.54167369],\n",
       "       [ 1.99916857, -0.45861556, -0.52449809, -0.47874634, -0.53730858],\n",
       "       [ 1.99915412, -0.453495  , -0.52248143, -0.48617279, -0.53700489],\n",
       "       [ 1.99932306, -0.46525128, -0.52093772, -0.47782564, -0.53530842],\n",
       "       [ 1.99911546, -0.45945967, -0.52397038, -0.47558735, -0.54009806],\n",
       "       [ 1.99925838, -0.46155894, -0.52205626, -0.47935227, -0.53629092],\n",
       "       [ 1.9992372 , -0.45748247, -0.52273633, -0.48393674, -0.53508166],\n",
       "       [ 1.99921107, -0.45831992, -0.52469247, -0.48102632, -0.53517235],\n",
       "       [ 1.999241  , -0.45941189, -0.52022663, -0.48200022, -0.53760226],\n",
       "       [ 1.99942529, -0.46746543, -0.51583583, -0.48128554, -0.53483849],\n",
       "       [ 1.99937619, -0.46647548, -0.51610053, -0.48016515, -0.53663503]])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z39NQp9dTyOp"
   },
   "source": [
    "### Report Accuracy of the predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zJL7Lgm-TyOp"
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate( x_test, y_test) \n",
    "\n",
    "print('\\ n loss:', scores[ 0]) \n",
    "\n",
    "print('\\ n accuracy:', scores[ 1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "R6_InternalLab_AIML.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
